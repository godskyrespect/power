import json
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from openai import OpenAI
import streamlit as st 
import config

# OpenAI ì—°ê²° ì„¤ì • ====================================
client = OpenAI(api_key=st.secrets.OPENAI_API_KEY)

# í•™ê³¼ì •ë³´ íŒŒì¼ ë¡œë“œ ===================================
file_path = './text.json'
with open(file_path, 'r', encoding='utf-8') as file:
    data = json.load(file)

# ê²€ìƒ‰ìœ¼ë¡œ ì‚¬ìš©í•  ë‚´ìš© ì¶”ì¶œ =============================
doc_list = [item['í•™ê³¼ì†Œê°œ'] for item in data]

## 1. FAISSë¥¼ ì´ìš©í•œ ì§ˆì˜ì™€ ìœ ì‚¬í•œ ë‚´ìš©ì„ ë²¡í„° ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜(get:ê²€ìƒ‰í•  ë‚´ìš©, return: ê²€ìƒ‰ëœ faissë¬¸ì„œ)
def search(query):
    embedding = OpenAIEmbeddings(api_key=st.secrets.OPENAI_API_KEY)
    faiss_vectorstore = FAISS.from_texts(
        doc_list, embedding, metadatas=[{"source": i} for i in range(len(doc_list))]
    )
    faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={"k":3})

    faiss_docs = faiss_retriever.invoke(query)

    return faiss_docs

## 2. í”„ë¡¬í”„íŠ¸ì— ë”°ë¥¸ LLMê²°ê³¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜(get: í”„ë¡¬í”„íŠ¸, return: streamlitì— ë§ëŠ” ëŒ€ë‹µ)
def chatgpt_generate(query):
    
    messages = [{
        "role": "system",
        "content": "You are a helpful assistant."
    },{
        "role": "user",
        "content": query
    }]
    response = client.chat.completions.create(model=st.session_state["openai_model"], messages=messages, stream=True)
    return response

## 3. ë¶€ì ì ˆí•œ í‘œí˜„ì´ ìˆìœ¼ë©´ 1ì„ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜(get: ì§ˆë¬¸, return: ë¶€ì ì ˆí•œí‘œí˜„ì¸ ê²½ìš° 1)
def slang_detector(query):
    messages = [{
        "role": "system",
        "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ìš•ì„¤, ì„±ì ì¸ í‘œí˜„, ì¸ì¢…ì°¨ë³„ë°œì–¸, ë“± ì ì ˆí•˜ì§€ ì•Šì€ í‘œí˜„ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤. ë§Œì•½ í•´ë‹¹ í‘œí˜„ì´ ìˆë‹¤ë©´ 1ì´ë¼ê³  ëŒ€ë‹µí•˜ì„¸ìš”."
    },{
        "role": "user",
        "content": query
    }
    ]
    response = client.chat.completions.create(model=st.session_state["openai_model"], messages=messages)
    answer = response.choices[0].message.content
    if answer == '1':
        return 1

## 4. ì§ˆë¬¸ê³¼ ê²€ìƒ‰ëœ ë‚´ìš©ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” í•¨ìˆ˜(get: ì§ˆë¬¸, docs: í•™ê³¼ì •ë³´ë¬¸ì„œ, return: í”„ë¡¬í”„íŠ¸)
def prompt_generator(query, docs):
    prompt = f"""
    ë‹¹ì‹ ì€ ê³ ë“±í•™êµ í•™ìƒë“¤ì˜ ì§„ë¡œì„¤ê³„ë¥¼ ë„ì™€ì£¼ëŠ” ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ ì…ë‹ˆë‹¤. 
    ë‹¹ì‹ ì´ í•´ì•¼ í•  ì¼ì€ ì‚¬ìš©ìê°€ ìì‹ ì˜ ê¿ˆì´ë‚˜ ì§„ë¡œì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•˜ë©´ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ê²€ìƒ‰ëœ ìë£Œë¥¼ ëª¨ë‘ ì¸ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
    Step1ì˜ ì¡°ê±´ì„ í™•ì¸í•˜ê³  Step2ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.
    Step1: ë§Œì•½ ì§ˆë¬¸ì— ìš•, ì„±ì ì¸ í‘œí˜„, ì°¨ë³„ì ì¸ ë°œì–¸, í•™ê³¼ ì¶”ì²œê³¼ ê´€ë ¨ì—†ëŠ” ì§ˆë¬¸(ex. ë‚˜ ì˜ˆë»?)ì´ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ í•´ë‹¹ ë‚´ìš©ì— ëŒ€í•´ ë‹µë³€ì„ í•  ìˆ˜ ì—†ë‹¤ê³  í•˜ì„¸ìš”.
    ì§ˆë¬¸ì´ ë‹¨ì–´ë¡œ ë˜ì–´ ìˆê±°ë‚˜ 2ê°œì˜ ë‹¨ì–´ ì´í•˜ì˜ ë¬¸ì¥ìœ¼ë¡œ ë˜ì–´ìˆë‹¤ë©´ ë„ˆë¬´ ì§§ì•„ì„œ ì˜ ëª¨ë¥´ê² ë‹¤ ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
    ì§ˆë¬¸ : {query}

    Step2: ê²€ìƒ‰ëœ ìë£Œì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì´ ìˆìŠµë‹ˆë‹¤. : í•™ê³¼ì´ë¦„, í•™ê³¼ì†Œê°œ, í•™ê³¼ì£¼ìš”êµê³¼ëª©, í•™ê³¼ê´€ë ¨ ê³ ë“±í•™êµ ì„ íƒê³¼ëª©, í•™ê³¼ê´€ë ¨ ì¶”ì²œ ë„ì„œ
    í•™ê³¼ë¥¼ ì•Œë ¤ì¤„ ë•ŒëŠ” ì•„ë˜ì— ìˆëŠ” ë¬¸ì„œ ë‚´ìš©ì„ ê³ ë“±í•™ìƒì—ê²Œ ì†Œê°œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
    """
    for i in range(len(docs)):
        idx = docs[i].metadata['source']
        prompt += f"{data[idx]['í•™ê³¼ëª…']}\n"
        prompt += f"í•™ê³¼ ì†Œê°œ: {docs[i].page_content}\n"
        prompt += f"í•™ê³¼ ê´€ë ¨ ì •ë³´: {data[idx]['í•™ê³¼ ê´€ë ¨ ì •ë³´']}\n"
        prompt += f"ê³ ë“±í•™êµ ì„ íƒ ê³¼ëª©: {data[idx]['í•™ê³¼ ê´€ë ¨ ê³ ë“±í•™êµ ì„ íƒ ê³¼ëª©']}\n"
        prompt += f"ì¶”ì²œë„ì„œ: {data[idx]['í•™ê³¼ ê´€ë ¨ ë„ì„œ ì¶”ì²œ']}\n"
        prompt += "\n"
        
    answer = chatgpt_generate(prompt)
    return answer

## Streamlit ì‚¬ì´íŠ¸ ì½”ë“œ ============================
st.info("ì´ í˜ì´ì§€ì—ì„œëŠ” AIí•œí…Œ ë‚´ê°€ ì›í•˜ëŠ” ëŒ€í•™êµ í•™ê³¼ì— ëŒ€í•´ì„œë§Œ ë¬¼ì–´ë³¼ ìˆ˜ ìˆì–´ìš”!", icon="ğŸ…")
st.title("ğŸ¤– ì§„ë¡œ ì„¤ê³„ ë„ìš°ë¯¸")
col1, col2 = st.columns([8, 2])
with col1:
    st.markdown("ë„ìš°ë¯¸ AI(ê°€ì¹­)ì€ ì‹¤ìˆ˜ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¤‘ìš”í•œ ì •ë³´ëŠ” ì„ ìƒë‹˜ê³¼ ê°™ì´ í™•ì¸í•˜ì„¸ìš”.")
    st.write("**ì§ˆë¬¸ ì˜ˆì‹œ** : OOí•™ê³¼ì— ëŒ€í•œ ì •ë³´ë¥¼ ìì„¸í•˜ê²Œ ì•Œë ¤ì¤˜.")

with col2:
    if st.button("ëŒ€í™” ì§€ìš°ê¸°"):
        st.session_state.messages.clear()
        st.rerun()

# 1. ìƒì„±í˜•AI ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-4o-mini"

# 2. ëŒ€í™”ë¥¼ ì§€ì†í•˜ê¸° ìœ„í•œ LISTìƒì„±í•˜ê¸°
if "messages" not in st.session_state:
    st.session_state.messages = []

# 3. ì—­í• ì— ë§ëŠ” ë©”ì‹œì§€ì°½ í‘œì‹œí•˜ê¸°
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])   

# 4. ì…ë ¥ì°½ì„ ë§Œë“¤ê³  ê²€ìƒ‰ê¸°ëŠ¥ êµ¬í˜„í•˜ê¸°
if prompt := st.chat_input('ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?'):
    with st.chat_message('user'):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # ë¶€ì ì ˆí•œ í‘œí˜„ì— ëŒ€í•œ ê²½ê³  ë©”ì‹œì§€
    if slang_detector(prompt) == 1:
        st.toast('ì ì ˆí•˜ì§€ ëª»í•œ í‘œí˜„ì€ ìì œí•˜ì„¸ìš”.', icon='ğŸš¨')

    # FAISS ê²€ìƒ‰ê¸°ë¥¼ ì´ìš©í•œ ë¬¸ì„œ ë‚´ìš©
    retrived = [doc for doc in search(prompt)]

    #ì§ˆë¬¸ì— ëŒ€í•œ ASSISTANTì— ëŒ€í•œ ì‘ë‹µ
    with st.chat_message('assistant'):
        answer = prompt_generator(prompt, retrived)
        response = st.write_stream(answer)
    st.session_state.messages.append({"role": "assistant", "content": response})
    
    
