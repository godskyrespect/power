import json
from langchain_community.retrievers import BM25Retriever
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from openai import OpenAI
import streamlit as st 
import random
import time

file = 'text.json'
# # st.chat_message ë©”ì‹œì§€ í˜•íƒœ ë„ìš°ê¸°  user: ì‚¬ìš©ì, assistant: GPT
# with st.chat_message("user"):
#     st.write("ì•ˆë…•í•˜ì„¸ì—¬~")
    
# with st.chat_message("assistant"):
#     st.write("ì¸ê°„ì‹œëŒ€ì˜ ëì´ ë„ë˜í–ˆë‹¤")
    
# # ì±„íŒ… ì…ë ¥ê¸° ë§Œë“¤ê¸°
# prompt = st.chat_input("ì•„ë¬´ê±°ë‚˜ ë¬¼ì–´ë³´ì„¸ìš”.")
# if prompt:
#     with st.chat_message("user"):
#         st.write(f'{prompt}')

# def response_generator():
#     response = "hello my name is chatgpt clone"
#     for word in response.split():
#         yield word + " "
#         time.sleep(0.05)
        
    
# # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”í•˜ê¸°
# if "messages" not in st.session_state:
#     st.session_state.messages = []

# for message in st.session_state.messages:
#     with st.chat_message(message['role']):
#         st.markdown(message['content'])
        
# # := í• ë‹¹í•˜ê³  ê°’ì„ ë°˜í™˜í•¨., ì‚¬ìš©ìê°€ ì…ë ¥í•˜ê³  í™”ë©´ì— ê¸°ì–µí•˜ëŠ” ì½”ë“œ
# if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
#     with st.chat_message('user'):
#         st.markdown(prompt)
#     st.session_state.messages.append({"role": "user", "content": prompt})
    
# #chatgptë¥¼ í†µí•´ì„œ ë‚˜ì˜¨ ëŒ€ë‹µì„ ë°›ìŠµë‹ˆë‹¤.
# response = f"Echo: {prompt}"

# # ì±—ë´‡ ë‹µë³€ì„ ì‘ì„±í•´ ì¤ë‹ˆë‹¤. 
# with st.chat_message("assistant"):
#     response = st.write_stream(response_generator())
# st.session_state.messages.append({"role": "assistant", "content": response})
key = st.text_input("APIí‚¤ ì…ë ¥í•˜ì„¸ìš”", "í›„ê´‘í›„ê´‘í›„")
st.title("ğŸ¦¾ CHATGPT 4o mini ë”°ë¼í•¨. ëˆë‚˜ê°€ë‹ˆê¹ ì ë‹¹íˆ ì“°ì„¸ìš”.")
api_key = key

with open(file, 'r', encoding='utf-8') as file:
    data = json.load(file)  # JSON ë°ì´í„°ë¥¼ Python ê°ì²´ë¡œ ë³€í™˜

# ë¶ˆëŸ¬ì˜¨ ë°ì´í„° í™•ì¸
#print(data)

doc_list = [item['í•™ê³¼ì†Œê°œ'] for item in data]

def search(query):
    # bm25_retriever = BM25Retriever.from_texts(
    #     doc_list, metadatas=[{"source": 1}]*len(doc_list)
    # )
    # bm25_retriever.k = 3


    embedding = OpenAIEmbeddings(api_key=api_key)
    faiss_vectorstore = FAISS.from_texts(
        doc_list, embedding, metadatas=[{"source": i} for i in range(len(doc_list))]
    )
    faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={"k":3})

    # bm25_docs = bm25_retriever.invoke(query)
    faiss_docs = faiss_retriever.invoke(query)

    # print(bm25_docs)
    return faiss_docs

def chatgpt_generate(query):
    
    messages = [{
        "role": "system",
        "content": "You are a helpful assistant."
    },{
        "role": "user",
        "content": query
    }]
    response = client.chat.completions.create(model=st.session_state["openai_model"], messages=messages, stream=True)
    return response


def prompt_generator(query, docs):
    prompt = f"""
    ë‹¹ì‹ ì€ ê³ ë“±í•™êµ í•™ìƒë“¤ì˜ ì§„ë¡œì„¤ê³„ë¥¼ ë„ì™€ì£¼ëŠ” ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ ì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì´ í•´ì•¼ í•  ì¼ì€ ì‚¬ìš©ìê°€ ìì‹ ì˜ ê¿ˆì´ë‚˜ ì§„ë¡œì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•˜ë©´ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ê²€ìƒ‰ëœ ìë£Œë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
    
    ê²€ìƒ‰ëœ ìë£Œì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì´ ìˆìŠµë‹ˆë‹¤. : í•™ê³¼ì´ë¦„, í•™ê³¼ì†Œê°œ, í•™ê³¼ì£¼ìš”êµê³¼ëª©, í•™ê³¼ê´€ë ¨ ê³ ë“±í•™êµ ì„ íƒê³¼ëª©, í•™ê³¼ê´€ë ¨ ì¶”ì²œ ë„ì„œ
    
    ì•„ë˜ì— ìˆëŠ” ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•™ê³¼ì— ëŒ€í•´ì„œ ê³ ë“±í•™ìƒì—ê²Œ ì†Œê°œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
    """
    for i in range(len(docs)):
        idx = docs[i].metadata['source']
        prompt += f"{data[idx]['í•™ê³¼ëª…']}\n"
        prompt += f"í•™ê³¼ ì†Œê°œ: {docs[i].page_content}\n"
        prompt += f"í•™ê³¼ ê´€ë ¨ ì •ë³´: {data[idx]['í•™ê³¼ ê´€ë ¨ ì •ë³´']}\n"
        prompt += f"ê³ ë“±í•™êµ ì„ íƒ ê³¼ëª©: {data[idx]['í•™ê³¼ ê´€ë ¨ ê³ ë“±í•™êµ ì„ íƒ ê³¼ëª©']}\n"
        prompt += f"ì¶”ì²œë„ì„œ: {data[idx]['í•™ê³¼ ê´€ë ¨ ë„ì„œ ì¶”ì²œ']}\n"
        prompt += "\n"
        
    answer = chatgpt_generate(prompt)
    return answer



if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-4o-mini"
    
if "messages" not in st.session_state:
    st.session_state.messages = []
    
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
if prompt := st.chat_input('ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?'):
    with st.chat_message('user'):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    retrived = [doc for doc in search(prompt)]
    with st.chat_message('assistant'):
        answer = prompt_generator(query, retrived)
        response = st.write_stream(answer)
    st.session_state.messages.append({"role": "assistant", "content": response})
