import json
from langchain_community.retrievers import BM25Retriever
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from openai import OpenAI
import streamlit as st 
import random
import time
import config


client = OpenAI(api_key=st.secrets.OPENAI_API_KEY)

file_path = './text.json'
with open(file_path, 'r', encoding='utf-8') as file:
    data = json.load(file)

doc_list = [item['í•™ê³¼ì†Œê°œ'] for item in data]
    
def search(query):
    # bm25_retriever = BM25Retriever.from_texts(
    #     doc_list, metadatas=[{"source": 1}]*len(doc_list)
    # )
    # bm25_retriever.k = 3


    embedding = OpenAIEmbeddings(api_key=st.secrets.OPENAI_API_KEY)
    faiss_vectorstore = FAISS.from_texts(
        doc_list, embedding, metadatas=[{"source": i} for i in range(len(doc_list))]
    )
    faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={"k":3})

    # bm25_docs = bm25_retriever.invoke(query)
    faiss_docs = faiss_retriever.invoke(query)

    # print(bm25_docs)
    return faiss_docs

def chatgpt_generate(query):
    
    messages = [{
        "role": "system",
        "content": "You are a helpful assistant."
    },{
        "role": "user",
        "content": query
    }]
    response = client.chat.completions.create(model=st.session_state["openai_model"], messages=messages, stream=True)
    return response
    
def slang_detector(query):
    messages = [{
        "role": "system",
        "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ìš•ì„¤, ì„±ì ì¸ í‘œí˜„, ì¸ì¢…ì°¨ë³„ë°œì–¸, ë“± ì ì ˆí•˜ì§€ ì•Šì€ í‘œí˜„ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤. ë§Œì•½ í•´ë‹¹ í‘œí˜„ì´ ìˆë‹¤ë©´ 1ì´ë¼ê³  ëŒ€ë‹µí•˜ì„¸ìš”."
    },{
        "role": "user",
        "content": query
    }
    ]
    response = client.chat.completions.create(model=st.session_state["openai_model"], messages=messages)
    answer = response.choices[0].message.content
    if answer == '1':
        return 1

def prompt_generator(query, docs):
    prompt = f"""
    ë‹¹ì‹ ì€ ê³ ë“±í•™êµ í•™ìƒë“¤ì˜ ì§„ë¡œì„¤ê³„ë¥¼ ë„ì™€ì£¼ëŠ” ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ ì…ë‹ˆë‹¤. 
    ë‹¹ì‹ ì´ í•´ì•¼ í•  ì¼ì€ ì‚¬ìš©ìê°€ ìì‹ ì˜ ê¿ˆì´ë‚˜ ì§„ë¡œì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•˜ë©´ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ê²€ìƒ‰ëœ ìë£Œë¥¼ ëª¨ë‘ ì¸ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
    Step1ì˜ ì¡°ê±´ì„ í™•ì¸í•˜ê³  Step2ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.
    Step1: ë§Œì•½ ì§ˆë¬¸ì— ìš•, ì„±ì ì¸ í‘œí˜„, ì°¨ë³„ì ì¸ ë°œì–¸, í•™ê³¼ ì¶”ì²œê³¼ ê´€ë ¨ì—†ëŠ” ì§ˆë¬¸(ex. ë‚˜ ì˜ˆë»?)ì´ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ í•´ë‹¹ ë‚´ìš©ì— ëŒ€í•´ ë‹µë³€ì„ í•  ìˆ˜ ì—†ë‹¤ê³  í•˜ì„¸ìš”.
    ì§ˆë¬¸ì´ ë‹¨ì–´ë¡œ ë˜ì–´ ìˆê±°ë‚˜ 2ê°œì˜ ë‹¨ì–´ ì´í•˜ì˜ ë¬¸ì¥ìœ¼ë¡œ ë˜ì–´ìˆë‹¤ë©´ ë„ˆë¬´ ì§§ì•„ì„œ ì˜ ëª¨ë¥´ê² ë‹¤ ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
    ì§ˆë¬¸ : {query}

    Step2: ê²€ìƒ‰ëœ ìë£Œì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì´ ìˆìŠµë‹ˆë‹¤. : í•™ê³¼ì´ë¦„, í•™ê³¼ì†Œê°œ, í•™ê³¼ì£¼ìš”êµê³¼ëª©, í•™ê³¼ê´€ë ¨ ê³ ë“±í•™êµ ì„ íƒê³¼ëª©, í•™ê³¼ê´€ë ¨ ì¶”ì²œ ë„ì„œ
    í•™ê³¼ë¥¼ ì•Œë ¤ì¤„ ë•ŒëŠ” ì•„ë˜ì— ìˆëŠ” ë¬¸ì„œ ë‚´ìš©ì„ ê³ ë“±í•™ìƒì—ê²Œ ì†Œê°œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
    """
    for i in range(len(docs)):
        idx = docs[i].metadata['source']
        prompt += f"{data[idx]['í•™ê³¼ëª…']}\n"
        prompt += f"í•™ê³¼ ì†Œê°œ: {docs[i].page_content}\n"
        prompt += f"í•™ê³¼ ê´€ë ¨ ì •ë³´: {data[idx]['í•™ê³¼ ê´€ë ¨ ì •ë³´']}\n"
        prompt += f"ê³ ë“±í•™êµ ì„ íƒ ê³¼ëª©: {data[idx]['í•™ê³¼ ê´€ë ¨ ê³ ë“±í•™êµ ì„ íƒ ê³¼ëª©']}\n"
        prompt += f"ì¶”ì²œë„ì„œ: {data[idx]['í•™ê³¼ ê´€ë ¨ ë„ì„œ ì¶”ì²œ']}\n"
        prompt += "\n"
        
    answer = chatgpt_generate(prompt)
    return answer

# # st.chat_message ë©”ì‹œì§€ í˜•íƒœ ë„ìš°ê¸°  user: ì‚¬ìš©ì, assistant: GPT
# with st.chat_message("user"):
#     st.write("ì•ˆë…•í•˜ì„¸ì—¬~")
    
# with st.chat_message("assistant"):
#     st.write("ì¸ê°„ì‹œëŒ€ì˜ ëì´ ë„ë˜í–ˆë‹¤")
    
# # ì±„íŒ… ì…ë ¥ê¸° ë§Œë“¤ê¸°
# prompt = st.chat_input("ì•„ë¬´ê±°ë‚˜ ë¬¼ì–´ë³´ì„¸ìš”.")
# if prompt:
#     with st.chat_message("user"):
#         st.write(f'{prompt}')

# def response_generator():
#     response = "hello my name is chatgpt clone"
#     for word in response.split():
#         yield word + " "
#         time.sleep(0.05)
        
    
# # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”í•˜ê¸°
# if "messages" not in st.session_state:
#     st.session_state.messages = []

# for message in st.session_state.messages:
#     with st.chat_message(message['role']):
#         st.markdown(message['content'])
        
# # := í• ë‹¹í•˜ê³  ê°’ì„ ë°˜í™˜í•¨., ì‚¬ìš©ìê°€ ì…ë ¥í•˜ê³  í™”ë©´ì— ê¸°ì–µí•˜ëŠ” ì½”ë“œ
# if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
#     with st.chat_message('user'):
#         st.markdown(prompt)
#     st.session_state.messages.append({"role": "user", "content": prompt})
    
# #chatgptë¥¼ í†µí•´ì„œ ë‚˜ì˜¨ ëŒ€ë‹µì„ ë°›ìŠµë‹ˆë‹¤.
# response = f"Echo: {prompt}"

# # ì±—ë´‡ ë‹µë³€ì„ ì‘ì„±í•´ ì¤ë‹ˆë‹¤. 
# with st.chat_message("assistant"):
#     response = st.write_stream(response_generator())
# st.session_state.messages.append({"role": "assistant", "content": response})

st.title("ğŸ¤– ì§„ë¡œ ì„¤ê³„ ë„ìš°ë¯¸")
col1, col2 = st.columns([8, 2])
with col1:
    st.write("ë„ìš°ë¯¸ AI(ê°€ì¹­)ì€ ì‹¤ìˆ˜ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¤‘ìš”í•œ ì •ë³´ëŠ” ì„ ìƒë‹˜ê³¼ ê°™ì´ í™•ì¸í•˜ì„¸ìš”.  **ì§ˆë¬¸ ì˜ˆì‹œ** : OOí•™ê³¼ì— ëŒ€í•œ ì •ë³´ë¥¼ ìì„¸í•˜ê²Œ ì•Œë ¤ì¤˜.")
    st.write("**ì§ˆë¬¸ ì˜ˆì‹œ** : OOí•™ê³¼ì— ëŒ€í•œ ì •ë³´ë¥¼ ìì„¸í•˜ê²Œ ì•Œë ¤ì¤˜.")

with col2:
    if st.button("ëŒ€í™” ì§€ìš°ê¸°"):
        st.session_state.messages.clear()
        st.rerun()

if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-4o-mini"
    
if "messages" not in st.session_state:
    st.session_state.messages = []
    
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])   


if prompt := st.chat_input('ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?'):
    with st.chat_message('user'):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})
    if slang_detector(prompt) == 1:
        st.toast('ì ì ˆí•˜ì§€ ëª»í•œ í‘œí˜„ì€ ìì œí•˜ì„¸ìš”.', icon='ğŸš¨')
        
    retrived = [doc for doc in search(prompt)]
    with st.chat_message('assistant'):
        answer = prompt_generator(prompt, retrived)
        response = st.write_stream(answer)
    st.session_state.messages.append({"role": "assistant", "content": response})
    
    
